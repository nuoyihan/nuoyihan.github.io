<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Violet Han</title> <meta name="author" content="Violet Han"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="violet han, violet yinuo han, yinuo han, hanyinuo"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/violet-favicon.png?6b472c93327e4b2d39c5455b7dcb5fca"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.violethan.com/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&amp;display=swap" rel="stylesheet"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Violet </span><span class="font-weight-bold">Han </span></a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">home</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/art/">art</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="publication-row"> <div class="publication-responsive-2cols"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/publication_preview/objectagents-480.webp 480w, /assets/img/publication_preview/objectagents-800.webp 800w, /assets/img/publication_preview/objectagents-1400.webp 1400w, " sizes="800px" type="image/webp"></source> <img src="/assets/img/publication_preview/objectagents.png" class="preview" width="100%" height="auto" alt="objectagents.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="publication-responsive-2cols"> <div id="objectagents"> <div class="title"><a href="https://www.violethan.com/publications/objectagents/">Towards Unobtrusive Physical AI: Augmenting Everyday Objects with Intelligence and Robotic Movement for Proactive Assistance</a></div> <div class="author"> <em>Violet Yinuo Han</em>, Jesse T. Gonzalez, Christina Yang, Zhiruo Wang, Scott E. Hudson, and Alexandra Ion</div> <div class="periodical"> <em>ACM UIST’25, Busan, Korea</em>, Sep 2025 </div> <div class="periodical"> </div> <br> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1145/3746059.3747726" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://interactive-structures.org/assets//publications/2025-09-object-agents/paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/sWMiPVagiBs?si=nOSvy_ckka45_lrF" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Users constantly interact with physical, most often passive, objects. Consider if familiar objects instead proactively assisted users, e.g., a stapler moving across the table to help users organize documents, or a knife moving away to prevent injury as the user is inatten- tively about to lean against the countertop. In this paper, we build on the qualities of tangible interaction and focus on recognizing user needs in everyday tasks to enable ubiquitous yet unobtrusive tangible interaction. To achieve this, we introduce an architecture that leverages large language models (LLMs) to perceive users’ environment and activities, perform spatial-temporal reasoning, and generate object actions aligned with inferred user intentions and object properties. We demonstrate the system’s utility provid- ing proactive assistance with multiple objects and in various daily scenarios. To evaluate our system components, we compare our system-generated output for user goal estimation and object action recommendation with human-annotated baselines, with results indicating good agreement.</p> </div> </div> </div> </div> </li> <li> <div class="publication-row"> <div class="publication-responsive-2cols"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/publication_preview/laymo-placeholder-480.webp 480w, /assets/img/publication_preview/laymo-placeholder-800.webp 800w, /assets/img/publication_preview/laymo-placeholder-1400.webp 1400w, " sizes="800px" type="image/webp"></source> <img src="/assets/img/publication_preview/laymo-placeholder.png" class="preview" width="100%" height="auto" alt="laymo-placeholder.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="publication-responsive-2cols"> <div id="Laymo"> <div class="title"><a href="https://www.violethan.com/publications/Laymo/">Transforming Everyday Objects into Dynamic Interfaces using Smart Flat-Foldable Structures</a></div> <div class="author"> <em>Violet Yinuo Han</em>, Amber Yinglei Chen, Mason Zadan, Jesse T. Gonzalez, Dinesh K. Patel, Wendy Fangyu Yu, Carmel Majidi, and Alexandra Ion</div> <div class="periodical"> <em>ACM UIST’25, Busan, Korea</em>, Sep 2025 </div> <div class="periodical"> </div> <br> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1145/3746059.3747720" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://interactive-structures.org/assets//publications/2025-09-laymo/paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/l0rnG6rc5NA?si=NPZ8_q2ykTpmxi2o" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Dynamic physical interfaces are often dedicated devices designed to adapt their physical properties to user needs. In this paper, we present an actuation system that allows users to transform their existing objects into dynamic physical user interfaces. We design our actuation system to integrate as a self-contained locomotion layer into existing objects that are small-scale, i.e., hand-size rather than furniture-size. We envision that such objects can act as col- laborators: as a studio assistant in a painter’s palette, as tutors in a student’s ruler, or as caretakers for plants evading direct sunlight. The key idea is to decompose the actuation into (1) energy input and (2) steering to achieve a flat form factor. The energy input is provided by simple vibration. We implement steering through differential friction controlled by flat-foldable compliant structures that can be activated electrically. We study the mechanism and its performance, and show its application scenarios enabling dynamic interactions with objects.</p> </div> </div> </div> </div> </li> <li> <div class="publication-row"> <div class="publication-responsive-2cols"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/publication_preview/dbn-placeholder-480.webp 480w, /assets/img/publication_preview/dbn-placeholder-800.webp 800w, /assets/img/publication_preview/dbn-placeholder-1400.webp 1400w, " sizes="800px" type="image/webp"></source> <img src="/assets/img/publication_preview/dbn-placeholder.png" class="preview" width="100%" height="auto" alt="dbn-placeholder.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="publication-responsive-2cols"> <div id="DBN"> <div class="title"><a href="https://www.violethan.com/publications/DBN/">A Dynamic Bayesian Network Based Framework for Multimodal Context-Aware Interactions</a></div> <div class="author"> <em>Violet Yinuo Han</em>, Tianyi Wang, Hyunsung Cho, Kashyap Todi, Ajoy Savio Fernandes, Andre Levi, Zheng Zhang, Tovi Grossman, Alexandra Ion, and Tanya Jonker</div> <div class="periodical"> <em>ACM IUI’25, Cagliari, Italy</em>, Mar 2025 </div> <div class="periodical"> </div> <br> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1145/3708359.3712070" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://interactive-structures.org/assets//publications/2025-03-dynamic-bayesian-network/paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/rb8KfYchya8?si=qsFLddGYjNZqMdGw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Multimodal context-aware interactions integrate multiple sensory inputs, such as gaze, gestures, speech, and environmental signals, to provide adaptive support across diverse user contexts. Building such systems is challenging due to the complexity of sensor fusion, real-time decision-making, and managing uncertainties from noisy inputs. To address these challenges, we propose a hybrid approach combining a dynamic Bayesian network (DBN) with a large language model (LLM). The DBN offers a probabilistic framework for modeling variables, relationships, and temporal dependencies, enabling robust, real-time inference of user intent, while the LLM incorporates world knowledge for contextual reasoning. We demonstrate our approach with a tri-level DBN implementation for tangible interactions, integrating gaze and hand actions to infer user intent in real time. A user evaluation with 10 participants in an everyday office scenario showed that our system can accurately and efficiently infer user intentions, achieving 0.83 per frame accuracy, even in complex environments. These results validate the effectiveness of the DBN+LLM framework for multimodal context-aware interactions.</p> </div> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="publication-row"> <div class="publication-responsive-2cols"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/publication_preview/rmm-preview-480.webp 480w, /assets/img/publication_preview/rmm-preview-800.webp 800w, /assets/img/publication_preview/rmm-preview-1400.webp 1400w, " sizes="800px" type="image/webp"></source> <img src="/assets/img/publication_preview/rmm-preview.jpg" class="preview" width="100%" height="auto" alt="rmm-preview.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="publication-responsive-2cols"> <div id="rmm"> <div class="title"><a href="https://www.violethan.com/publications/rmm/">Robotic Metamaterials: A Modular System for Hands-On Configuration of Ad-Hoc Dynamic Applications</a></div> <div class="author"> Zhitong Cui, Shuhong Wang, <em>Violet Yinuo Han</em>, Tucker Rae-Grant, Willa Yunqi Yang, Alan Zhu, Scott E. Hudson, and Alexandra Ion</div> <div class="periodical"> <em>ACM CHI’24, Honolulu, HI</em>, May 2024 </div> <div class="periodical"> </div> <br> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1145/3613904.3642891" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/doi/pdf/10.1145/3613904.3642891" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/DmH4AIIZ42U?si=R5abVVefKTwhFeG6" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>We propose augmenting initially passive structures built from simple repeated cells, with novel active units to enable dynamic, shape-changing, and robotic applications. Inspired by metamaterials that can employ mechanisms, we build a framework that allows users to configure cells of this passive structure to allow it to perform complex tasks. A key benefit is that our structures can be repeatedly (re)configured by users inserting our configuration units to turn the passive material into, e.g., locomotion robots, integrated motion platforms, or interactive interfaces, as we demonstrate in this paper.</p> </div> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="publication-row"> <div class="publication-responsive-2cols"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/publication_preview/blendmr-preview-480.webp 480w, /assets/img/publication_preview/blendmr-preview-800.webp 800w, /assets/img/publication_preview/blendmr-preview-1400.webp 1400w, " sizes="800px" type="image/webp"></source> <img src="/assets/img/publication_preview/blendmr-preview.png" class="preview" width="100%" height="auto" alt="blendmr-preview.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="publication-responsive-2cols"> <div id="blendmr"> <div class="title"><a href="https://www.violethan.com/publications/blendmr/">BlendMR: A Computational Method to Create Ambient Mixed Reality Interfaces</a></div> <div class="award"> <i class="fa-solid fa-trophy"></i> Best Paper Award</div> <div class="author"> <em>Violet Yinuo Han</em>, Hyunsung Cho, Kiyosu Maeda, Alexandra Ion, and David Lindlbauer</div> <div class="periodical"> <em>ACM ISS’23, Pittsburgh, PA</em>, Nov 2023 </div> <div class="periodical"> </div> <br> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1145/3626472" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/doi/pdf/10.1145/3626472" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/3vQCdW7UCN8?si=50VJPeZ1Jm63qOiC" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://youtu.be/mO8k760D6oQ?si=8KK_6ueyyATOJiVV" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Talk</a> </div> <div class="abstract hidden"> <p>Mixed Reality (MR) systems display content freely in space, and present nearly arbitrary amounts of information, enabling ubiquitous access to digital information. This approach, however, introduces clutter and distraction if too much virtual content is shown. We present BlendMR, an optimization-based MR system that blends virtual content onto the physical objects in users’ environments for ambient information display. Our approach takes existing 2D applications and meshes of physical objects as input. It analyses the geometry of the physical objects and identifies regions that are suitable hosts for virtual elements. Using a novel integer programming formulation, our approach then optimally maps selected contents of the 2D applications onto the object, optimizing for factors such as importance and hierarchy of information, viewing angle, and geometric distortion. We evaluate BlendMR by comparing it to a 2D window baseline. Study results show that BlendMR decreases clutter and distraction, and is preferred by users. We demonstrate the applicability of BlendMR in a series of results and usage scenarios.</p> </div> </div> </div> </div> </li> <li> <div class="publication-row"> <div class="publication-responsive-2cols"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/publication_preview/parametrichaptics-preview-480.webp 480w, /assets/img/publication_preview/parametrichaptics-preview-800.webp 800w, /assets/img/publication_preview/parametrichaptics-preview-1400.webp 1400w, " sizes="800px" type="image/webp"></source> <img src="/assets/img/publication_preview/parametrichaptics-preview.png" class="preview" width="100%" height="auto" alt="parametrichaptics-preview.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="publication-responsive-2cols"> <div id="parametrichaptics"> <div class="title"><a href="https://www.violethan.com/publications/parametrichaptics/">Parametric Haptics: Versatile Geometry-Based Tactile Feedback Devices</a></div> <div class="author"> <em>Violet Yinuo Han</em>, Abena Boadi-Agyemang, Yuyu Lin, David Lindlbauer, and Alexandra Ion</div> <div class="periodical"> <em>ACM UIST’23, San Francisco, CA</em>, Nov 2023 </div> <div class="periodical"> </div> <br> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1145/3586183.3606766" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/doi/pdf/10.1145/3586183.3606766" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/PIUCEdw4UqA?si=QcH5uaiibO217Xpx" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://www.youtube.com/live/YzCC3NcGVrM?si=7Sl__0gcBOxCvi0V&amp;t=15004" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Talk</a> </div> <div class="abstract hidden"> <p>Haptic feedback is important for immersive, assistive, or multimodal interfaces, but engineering devices that generalize across applications is notoriously difficult. To address the issue of versatility, we propose Parametric Haptics, geometry-based tactile feedback devices that are customizable to render a variety of tactile sensations. To achieve this, we integrate the actuation mechanism with the tactor geometry into passive 3D printable patches, which are then connected to a generic wearable actuation interface consisting of micro gear motors. The key benefit of our approach is that the 3D-printed patches are modular, can consist of varying numbers and shapes of tactors, and that the tactors can be grouped and moved by our actuation geometry over large areas of the skin. The patches are soft, thin, conformable, and easy to customize to different use cases, thus potentially enabling a large design space of diverse tactile sensations. In our user study, we investigate the mapping between geometry parameters of our haptic patches and users’ tactile perceptions. Results indicate a good agreement between our parameters and the reported sensations, showing initial evidence that our haptic patches can produce a wide range of sensations for diverse use scenarios. We demonstrate the utility of our approach with wearable prototypes in immersive Virtual Reality (VR) scenarios, embedded into wearable objects such as glasses, and as wearable navigation and notification interfaces. We support designing such patches with a design tool in Rhino.</p> </div> </div> </div> </div> </li> <li> <div class="publication-row"> <div class="publication-responsive-2cols"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/publication_preview/permeablesensors-preview-480.webp 480w, /assets/img/publication_preview/permeablesensors-preview-800.webp 800w, /assets/img/publication_preview/permeablesensors-preview-1400.webp 1400w, " sizes="800px" type="image/webp"></source> <img src="/assets/img/publication_preview/permeablesensors-preview.png" class="preview" width="100%" height="auto" alt="permeablesensors-preview.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="publication-responsive-2cols"> <div id="permeablesensors"> <div class="title"><a href="https://www.violethan.com/publications/permeablesensors/">Permeable Thermistor Temperature Sensors Based on Porous Melamine Foam</a></div> <div class="author"> Hugo Souza Oliveira, Niloofar Saeedzadeh Khaanghah, <em>Violet Yinuo Han</em>, Alejandro Carrasco-Pena, Alexandra Ion, Michael Haller, Giuseppe Cantarella, and Niko Münzenrieder</div> <div class="periodical"> <em>IEEE Sensors Letters</em>, Nov 2023 </div> <div class="periodical"> </div> <br> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1109/LSENS.2023.3271590" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Flexible sensors and electronics have gained much attention in recent years. They are especially interesting due to their abilities to conform to static and dynamic surfaces while keeping their functionality. These characteristics make them relevant for a wide range of applications, from health care and fitness monitoring to soft robotics. In this work, we go beyond simple mechanical flexibility and present a lightweight and permeable flexible sensor utilizing melamine foam as a substrate. The foam is coated with metallic copper (Cu) and semiconductive Indium-Gallium-Zinc-Oxide (InGaZnO) to form a thermistor-type temperature sensor. The sensor showed a very stable response when cycling the temperature between 25 °C and 51 °C, exhibiting a maximum sensitivity of −01.6%∘C−1 , a permeability of 366.6gm−2h−1 at 24 °C, and a maximum resistance variation of −2.9%RH−1 when varying the relative humidity from 40% to 70%. The device also remained fully functional even after being bent to a radius of 5 mm.</p> </div> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Violet Han. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>, based on <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Violet Han</title> <meta name="author" content="Violet Han"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="violet han, violet yinuo han, yinuo han, hanyinuo"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/violet-favicon.png?6b472c93327e4b2d39c5455b7dcb5fca"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.violethan.com/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&amp;display=swap" rel="stylesheet"> </head> </html>